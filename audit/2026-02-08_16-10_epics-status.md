<!--
Audit Report
Generated: 2026-02-08 16:10:19
Git Commit: c98f36e1bfef8a4eab96071e29ca42f83f5d033c
Scope: feature/epics-status
Invoked: /audit epics-status
-->

# Project Audit Report

Date: 2026-02-08
Project: nextstat.io
Auditor: Codex
Scope: feature (status check for 5 in-progress epics)
Git Commit: c98f36e1bfef8a4eab96071e29ca42f83f5d033c

---

## Executive Summary

- Critical: 0
- Major: 3
- Minor: 2
- Total: 5

Overall Health Score: 78/100
Top risks: HistFactory XML `ConstraintTerm` is not parsed (Gamma/LogNormal), and Metal lacks a single-model MLE/scan path despite compute-layer primitives existing.

---

## Major Issues

### [HistFactory XML] `ConstraintTerm` (Gamma/LogNormal/Gaussian) is not imported into measurement config
- File: crates/ns-translate/src/histfactory/combination.rs:15
- Evidence: `MeasurementXml` only records `name/poi/lumi/lumi_rel_err/param_settings`; parser reads `<POI>` and `<ParamSetting>` only (no `<ConstraintTerm>` handling).
- Impact: HistFactory exports that rely on `<ConstraintTerm Type="Gamma|LogNormal" RelativeUncertainty="...">param</ConstraintTerm>` will silently drop the prior/constraint information in the produced pyhf-style `workspace.json`.
- Fix: Extend `parse_measurement()` to parse `<ConstraintTerm>` nodes (type + relative uncertainty + param name list) and thread it into `builder.rs::build_measurements()` so `ParameterConfig.{auxdata,sigmas}` reflect the constraint semantics.
- Confidence: high

### [GPU/Metal] Metal f32 single-model fit path is missing at the inference layer
- File: crates/ns-inference/src/lib.rs:76
- Evidence: only `gpu_single` is exported under `#[cfg(feature = "cuda")]`; there is no Metal analogue. CUDA `GpuSession` hardcodes `CudaBatchAccelerator` (see `crates/ns-inference/src/gpu_single.rs`), while Metal only has batch toy fitting (`metal_batch`) and a profiled differentiable session (`metal_differentiable`).
- Impact: single-model `fit` / `scan` / “ranking”-style workflows cannot use Metal even though Metal batch kernels exist (f32).
- Fix: Add a Metal single-model session wrapper (likely mirroring `gpu_single.rs`) backed by `ns_compute::metal_batch::MetalBatchAccelerator::single_nll_grad()` and wire it into MLE + profile scan entry points.
- Confidence: high

### [GPU/Architecture] Device-agnostic `GpuAccelerator` trait + generic `GpuSession` refactor is not implemented (doc-only)
- File: docs/internal/plans/metal-batch-gpu.md:37
- Evidence: the plan specifies `crates/ns-compute/src/gpu_accel.rs` and `crates/ns-inference/src/gpu_session.rs`, but these files/modules do not exist; CUDA single-fit code remains concrete over `CudaBatchAccelerator`.
- Impact: Metal single-model fit will likely duplicate CUDA’s `GpuSession`/`GpuObjective` logic unless the abstraction is implemented first.
- Fix: Implement the `GpuAccelerator` trait and generic `GpuSession<A>` as in the plan, then provide CUDA+Metal impls.
- Confidence: high

## Minor Issues

### [GPU/Phase 2C] `ComputeBackend`-style CUDA/Metal backends are stubs (separate from working accelerators)
- File: crates/ns-compute/src/cuda.rs:1
- Evidence: `CudaBackend` / `MetalBackend` implement `ComputeBackend` but return `Error::NotImplemented` for `nll/gradient/hessian`.
- Impact: any code path expecting to use `ns_compute::{cuda, metal}` as a `ComputeBackend` will not work; GPU usage currently relies on dedicated accelerator modules (batch/differentiable).
- Fix: Either (a) implement `ComputeBackend` via the accelerators, or (b) clearly deprecate/remove the stub modules to avoid confusion.
- Confidence: high

### [TREx/NTUP Expr] Short-circuit exists, but SIMD/vectorized bulk evaluation falls back to row-wise when control flow is present
- File: crates/ns-root/src/expr.rs:600
- Evidence: `&&/||` compile to `Jz/Jmp` instructions; `eval_bytecode_bulk` falls back to row-wise when bytecode contains `Jz/Jmp/DynLoad`.
- Impact: expressions using boolean short-circuit or dynamic indexing lose the fast vectorized path (perf gap; not a correctness bug).
- Fix: (Optional) implement a mask-based vectorized evaluator for control-flow ops, or accept the fallback as the contract.
- Confidence: medium

---

## Feature Checklist

### HistFactory XML Import Parity — ConstraintTerm (Gamma/LogNormal/Gaussian)
- [ ] Backend API complete
- [ ] Frontend UI complete
- [ ] Wiring verified
- [ ] Error handling
- [ ] Tests
- [ ] Docs

### Performance & Robustness — Metal f32 single-model fit
- [ ] Backend API complete
- [ ] Frontend UI complete
- [ ] Wiring verified
- [ ] Error handling
- [ ] Tests
- [ ] Docs

### Metal GPU Full Backend — GpuAccelerator + Generic GpuSession + Metal single fit
- [ ] Backend API complete
- [ ] Frontend UI complete
- [ ] Wiring verified
- [ ] Error handling
- [ ] Tests
- [ ] Docs

### CUDA backend (Phase 2C)
- [ ] Backend API complete
- [ ] Frontend UI complete
- [ ] Wiring verified
- [ ] Error handling
- [ ] Tests
- [ ] Docs

### TREx Replacement — vector branches, expr short-circuit + SIMD
- [x] Backend API complete
- [ ] Frontend UI complete
- [ ] Wiring verified
- [ ] Error handling
- [ ] Tests
- [ ] Docs

## Unverified Areas

- GPU runtime behavior (Metal/CUDA) not executed in this audit; assessment is code-only.
- CLI/user-facing flags for selecting Metal/CUDA for single-model fits were not exercised.

## Files Reviewed

- crates/ns-translate/src/histfactory/combination.rs
- crates/ns-translate/src/histfactory/builder.rs
- tests/fixtures/pyhf_xmlimport/config/example.xml
- crates/ns-inference/src/lib.rs
- crates/ns-inference/src/gpu_single.rs
- crates/ns-inference/src/profile_likelihood.rs
- crates/ns-inference/src/metal_batch.rs
- crates/ns-compute/src/metal_batch.rs
- crates/ns-compute/src/cuda.rs
- crates/ns-compute/src/metal.rs
- crates/ns-root/src/file.rs
- crates/ns-root/src/branch_reader.rs
- crates/ns-root/src/expr.rs
- crates/ns-root/tests/read_vector_tree.rs
- docs/internal/plans/metal-batch-gpu.md
- docs/references/trex_expr_support.md

## Recommendations

1. Priority 1: Implement HistFactory XML `<ConstraintTerm>` parsing + mapping (Gamma/LogNormal/Gaussian) and add fixture-based tests.
2. Priority 2: Implement Metal single-model MLE session (use `MetalBatchAccelerator` single-eval helpers) and wire to scan/ranking entry points.
3. Priority 3: Before duplicating code, implement the `GpuAccelerator` + generic `GpuSession` refactor (doc plan → code).

