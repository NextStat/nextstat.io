<!--
Audit Report
Generated: 2026-02-07 19:25:07
Git Commit: 181db78d7897ee14f21028cfa4591a2b1b8fb740
Scope: full
Invoked: /audit full
-->

# Project Audit Report

Date: 2026-02-07
Project: NextStat
Auditor: Codex
Scope: full
Git Commit: 181db78d7897ee14f21028cfa4591a2b1b8fb740

---

## Executive Summary

- Critical: 0
- Major: 4
- Minor: 4
- Total: 8

Overall Health Score: 70/100
Top risks: ROOT decompression missing ZSTD/XZ support; nuisance ranking is slow and potentially misleading; GPU warm-start fit returns zero uncertainties; GPU NormSys serialization silently degrades on invalid inputs.

---

## Critical Issues

(none found)

## Major Issues

### [Correctness/Compatibility] ROOT decompression advertises ZSTD/XZ but only implements zlib/LZ4
- File: crates/ns-root/src/decompress.rs:1
- Evidence: Docstring claims support for `"XZ"` and `"ZS"` tags, but the dispatch only matches `b"ZL"` and `b"L4"` and errors otherwise. See dispatch at crates/ns-root/src/decompress.rs:37.
- Impact: Reading ROOT files that use ZSTD (`"ZS"`) or LZMA/XZ (`"XZ"`) compression will fail at runtime; this undermines the “native ROOT reader” promise for modern ROOT data.
- Fix:
  1. Either implement `"ZS"` (zstd) and `"XZ"` (lzma/xz) support, or
  2. Update docs + errors to accurately reflect supported algorithms and add a preflight check/error message that guides the user.
- Confidence: high

### [Performance/Correctness] Nuisance ranking does full Hessian fits per NP and mixes constrained/unconstrained parameters with heuristic sigmas
- File: crates/ns-inference/src/mle.rs:640
- Evidence:
  - Ranking runs `self.fit(...)` for nominal + each NP ±1σ (crates/ns-inference/src/mle.rs:644, 671, 676), which computes a full Hessian/covariance each time.
  - NP selection includes *any* non-POI param with non-degenerate bounds (crates/ns-inference/src/mle.rs:651-657), not just constrained nuisances; for missing constraints it falls back to `init` and a heuristic sigma (crates/ns-inference/src/mle.rs:664-668).
- Impact:
  - Ranking can become prohibitively slow on realistic models (hundreds of params) and may be unusable in “fast sensitivity” workflows.
  - Results can be misleading because unconstrained parameters get arbitrary ±1σ definitions, and constrained vs unconstrained are not distinguished in the output.
- Fix:
  1. Change per-NP refits to use a “minimum-only” path (e.g. `fit_minimum_*`) and avoid Hessian computation for NP up/down points.
  2. Filter to truly constrained nuisance parameters by default; optionally provide an explicit mode for unconstrained parameters with a required user-specified sigma policy.
  3. Warm-start consecutive fits and reuse an AD tape per thread (similar to `profile_likelihood::scan_histfactory`).
- Confidence: high

### [API Correctness] Python `fit(..., device="cuda", init_pars=...)` returns zero uncertainties without signaling “uncertainties not computed”
- File: bindings/ns-py/src/lib.rs:3832
- Evidence: In the CUDA warm-start branch, the result is constructed with `vec![0.0; m.n_params()]` uncertainties (bindings/ns-py/src/lib.rs:3862-3870).
- Impact: Downstream consumers may treat uncertainties as real values (plots, ranking/pulls, model cards). Silent zeros can corrupt evaluation, comparisons, and experiment tracking.
- Fix:
  1. Compute uncertainties for the warm-start path (reuse the existing GPU session + Hessian fallback logic), or
  2. Extend `FitResult` to represent “uncertainties unavailable” and surface that through the Python API (preferred if you want a true “fit_minimum” API).
- Confidence: high

### [Validation/GPU] GPU NormSys serialization accepts invalid factors and silently stores placeholder logs
- File: crates/ns-translate/src/pyhf/model.rs:2652
- Evidence: For `hi_factor <= 0` or `lo_factor <= 0`, the serializer logs a warning and stores a linear fallback with `ln_hi/ln_lo = 0.0` placeholders (crates/ns-translate/src/pyhf/model.rs:2658-2677).
- Impact: GPU results can silently diverge from CPU semantics on invalid workspaces; “warn + continue” is easy to miss in pipelines and can poison comparisons.
- Fix:
  1. Prefer hard validation: reject non-positive factors at model-build time (CPU + GPU paths).
  2. If a fallback is intentionally supported, propagate an explicit “degraded” flag into outputs/bundles so callers can gate on it.
- Confidence: high

## Minor Issues

### [Safety/Maintainability] `unsafe impl Send/Sync` used to satisfy optimizer bounds with `RefCell` internals
- File: crates/ns-inference/src/mle.rs:263
- Evidence: `HFObjective` uses `RefCell<Tape>` and `RefCell<NllScratch>` and declares `unsafe impl Send`/`Sync` with a comment asserting single-threaded execution (crates/ns-inference/src/mle.rs:263-266).
- Impact: This is brittle if the optimizer or call sites become multi-threaded; incorrect assumptions here can become UB.
- Fix: Consider relaxing `ObjectiveFunction` bounds (crates/ns-inference/src/optimizer.rs:60) or encapsulate interior mutability behind thread-local state passed explicitly, so `unsafe` is not required.
- Confidence: medium

### [Stubs/Expectations] Compute backends `cuda`/`metal` are compile-time stubs returning `Error::NotImplemented`
- File: crates/ns-compute/src/cuda.rs:1
- Evidence: Both backends implement `ComputeBackend` but return `Error::NotImplemented` for `nll/gradient/hessian` (crates/ns-compute/src/cuda.rs:19, crates/ns-compute/src/metal.rs:19).
- Impact: Feature flags may give a false impression that generic GPU backends exist; users can enable features and still get runtime “NotImplemented”.
- Fix: Make stubs impossible to reach from public APIs (compile-time gating), or clearly document “stub only” in README/docs and in error messages.
- Confidence: high

### [Robustness] HistFactory XML builder uses `unwrap()` for ROOT cache lookups
- File: crates/ns-translate/src/histfactory/builder.rs:63
- Evidence: After inserting into `root_cache`, it does `root_cache.get(&root_path).unwrap()` (also at crates/ns-translate/src/histfactory/builder.rs:335).
- Impact: Logic is likely correct today, but `unwrap()` in library code turns “should never happen” into a hard panic.
- Fix: Replace with `get(...).ok_or_else(|| Error::RootFile(...))?` to keep errors recoverable.
- Confidence: medium

### [CI/Quality] Python stub-generation workflow is a placeholder
- File: .github/workflows/python-tests.yml:78
- Evidence: The stub-generation job prints “will be added in Phase 1” and does not generate/validate stubs.
- Impact: Drift risk between Rust bindings and `*_core.pyi` / type hints if not gated.
- Fix: Add an actual stub generation/verification step (or remove the job until ready).
- Confidence: high

## Feature Checklist

### Differentiable “Loss Layer” (PyTorch/JAX)
- [ ] Backend API complete (gradients w.r.t. *inputs* like hist/bin yields, not only params)
- [ ] Python bindings complete (autograd integration)
- [ ] Wiring verified with a training-loop example
- [ ] Error handling (NaNs, nonpositive rates, nonconvergence)
- [ ] Tests (gradcheck vs finite differences)
- [ ] Docs (end-to-end example)

### Fast Nuisance Ranking / Sensitivity
- [x] Backend API exists (`MaximumLikelihoodEstimator::ranking`)
- [ ] Performance acceptable on realistic models (avoid Hessian per refit; warm-start; tape reuse)
- [ ] Correct semantics (constrained-only by default; sigma definition explicit)
- [ ] Tests (contract + perf regression)
- [ ] Docs (interpretation guidance)

### Experiment Tracking / JSON Metrics
- [x] CLI already emits JSON summaries in multiple commands
- [ ] Standardized machine-readable schema for “fit/hypotest/limits” outputs across commands
- [ ] Optional adapters (W&B/MLflow) without hard dependencies
- [ ] Docs (examples for sweeps/grid search)

### Gymnasium RL Environment
- [ ] Environment wrapper exists
- [ ] Deterministic seeding + reproducible episodes
- [ ] Reward definition documented and stable
- [ ] Tests (API contract)
- [ ] Example agent (baseline)

## Unverified Areas

- GPU runtime behavior (CUDA/Metal) could not be exercised here; review is code-only.
- Real-world ROOT corpus coverage for compression algorithms beyond ZL/L4.

## Files Reviewed

- /Users/andresvlc/WebDev/nextstat.io/README.md
- /Users/andresvlc/WebDev/nextstat.io/Cargo.toml
- /Users/andresvlc/WebDev/nextstat.io/crates/ns-inference/src/mle.rs
- /Users/andresvlc/WebDev/nextstat.io/crates/ns-inference/src/optimizer.rs
- /Users/andresvlc/WebDev/nextstat.io/crates/ns-inference/src/profile_likelihood.rs
- /Users/andresvlc/WebDev/nextstat.io/crates/ns-translate/src/pyhf/model.rs
- /Users/andresvlc/WebDev/nextstat.io/crates/ns-translate/src/histfactory/builder.rs
- /Users/andresvlc/WebDev/nextstat.io/crates/ns-root/src/file.rs
- /Users/andresvlc/WebDev/nextstat.io/crates/ns-root/src/decompress.rs
- /Users/andresvlc/WebDev/nextstat.io/crates/ns-compute/src/cuda.rs
- /Users/andresvlc/WebDev/nextstat.io/crates/ns-compute/src/metal.rs
- /Users/andresvlc/WebDev/nextstat.io/crates/ns-viz/src/ranking.rs
- /Users/andresvlc/WebDev/nextstat.io/bindings/ns-py/src/lib.rs
- /Users/andresvlc/WebDev/nextstat.io/bindings/ns-py/python/nextstat/__init__.py
- /Users/andresvlc/WebDev/nextstat.io/bindings/ns-py/python/nextstat/viz.py
- /Users/andresvlc/WebDev/nextstat.io/.github/workflows/rust-tests.yml
- /Users/andresvlc/WebDev/nextstat.io/.github/workflows/python-tests.yml

## Recommendations

1. Priority 1: Fix ROOT decompression algorithm support (implement ZSTD/XZ or correct docs + explicit gating).
2. Priority 2: Rework ranking to be fast + semantically constrained-only by default.
3. Priority 3: Fix CUDA warm-start `fit` to not return silent-zero uncertainties.

