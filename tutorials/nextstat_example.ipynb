{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NextStat: Full Analysis Tutorial\n",
    "\n",
    "This tutorial walks through a complete HistFactory analysis using NextStat — from workspace construction to publication-quality plots.\n",
    "\n",
    "Analogous to the [cabinetry tutorial](https://github.com/scikit-hep/cabinetry/blob/master/docs/tutorials/example.ipynb), but using NextStat's Rust-powered engine.\n",
    "\n",
    "### What you'll learn\n",
    "1. Build a pyhf-compatible workspace\n",
    "2. Inspect the model (parameters, modifiers, channels)\n",
    "3. Run an MLE fit\n",
    "4. Generate pulls, ranking, correlation, and distribution plots\n",
    "5. Perform profile likelihood scans and CLs exclusion\n",
    "6. Use the native Rust renderer with ATLAS/CMS/NextStat themes\n",
    "7. Export results to SVG/PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (Colab / first run)\n",
    "# !pip install -q nextstat numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import nextstat\n",
    "\n",
    "print(f\"NextStat version: {nextstat.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a Workspace\n",
    "\n",
    "We create a two-channel HistFactory workspace with signal + two backgrounds,\n",
    "normalization and shape systematics, and simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Channel 1: Signal Region (6 bins)\n",
    "sr_signal = np.array([2.0, 8.0, 15.0, 12.0, 5.0, 1.0])\n",
    "sr_ttbar  = np.array([20.0, 45.0, 60.0, 55.0, 30.0, 10.0])\n",
    "sr_wjets  = np.array([5.0, 10.0, 8.0, 6.0, 4.0, 2.0])\n",
    "sr_total  = sr_signal + sr_ttbar + sr_wjets\n",
    "sr_data   = np.random.poisson(sr_total).astype(float)\n",
    "\n",
    "# Channel 2: Control Region (4 bins) — no signal\n",
    "cr_ttbar = np.array([80.0, 120.0, 90.0, 40.0])\n",
    "cr_wjets = np.array([15.0, 25.0, 20.0, 10.0])\n",
    "cr_total = cr_ttbar + cr_wjets\n",
    "cr_data  = np.random.poisson(cr_total).astype(float)\n",
    "\n",
    "# Shape systematic: ttbar modeling (10% shape variation)\n",
    "sr_ttbar_up   = sr_ttbar * np.array([1.05, 1.08, 1.12, 1.10, 1.06, 1.03])\n",
    "sr_ttbar_down = sr_ttbar * np.array([0.95, 0.92, 0.88, 0.90, 0.94, 0.97])\n",
    "cr_ttbar_up   = cr_ttbar * np.array([1.06, 1.10, 1.08, 1.04])\n",
    "cr_ttbar_down = cr_ttbar * np.array([0.94, 0.90, 0.92, 0.96])\n",
    "\n",
    "workspace = {\n",
    "    \"channels\": [\n",
    "        {\n",
    "            \"name\": \"SR\",\n",
    "            \"samples\": [\n",
    "                {\n",
    "                    \"name\": \"signal\",\n",
    "                    \"data\": sr_signal.tolist(),\n",
    "                    \"modifiers\": [\n",
    "                        {\"name\": \"mu\", \"type\": \"normfactor\", \"data\": None},\n",
    "                        {\"name\": \"lumi\", \"type\": \"normsys\", \"data\": {\"hi\": 1.02, \"lo\": 0.98}},\n",
    "                    ],\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"ttbar\",\n",
    "                    \"data\": sr_ttbar.tolist(),\n",
    "                    \"modifiers\": [\n",
    "                        {\"name\": \"ttbar_norm\", \"type\": \"normsys\", \"data\": {\"hi\": 1.05, \"lo\": 0.95}},\n",
    "                        {\"name\": \"ttbar_modeling\", \"type\": \"histosys\", \"data\": {\n",
    "                            \"hi_data\": sr_ttbar_up.tolist(),\n",
    "                            \"lo_data\": sr_ttbar_down.tolist(),\n",
    "                        }},\n",
    "                        {\"name\": \"lumi\", \"type\": \"normsys\", \"data\": {\"hi\": 1.02, \"lo\": 0.98}},\n",
    "                        {\"name\": \"staterror_SR\", \"type\": \"staterror\", \"data\": np.sqrt(sr_ttbar).tolist()},\n",
    "                    ],\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"wjets\",\n",
    "                    \"data\": sr_wjets.tolist(),\n",
    "                    \"modifiers\": [\n",
    "                        {\"name\": \"wjets_norm\", \"type\": \"normsys\", \"data\": {\"hi\": 1.10, \"lo\": 0.90}},\n",
    "                        {\"name\": \"lumi\", \"type\": \"normsys\", \"data\": {\"hi\": 1.02, \"lo\": 0.98}},\n",
    "                    ],\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"CR\",\n",
    "            \"samples\": [\n",
    "                {\n",
    "                    \"name\": \"ttbar\",\n",
    "                    \"data\": cr_ttbar.tolist(),\n",
    "                    \"modifiers\": [\n",
    "                        {\"name\": \"ttbar_norm\", \"type\": \"normsys\", \"data\": {\"hi\": 1.05, \"lo\": 0.95}},\n",
    "                        {\"name\": \"ttbar_modeling\", \"type\": \"histosys\", \"data\": {\n",
    "                            \"hi_data\": cr_ttbar_up.tolist(),\n",
    "                            \"lo_data\": cr_ttbar_down.tolist(),\n",
    "                        }},\n",
    "                        {\"name\": \"lumi\", \"type\": \"normsys\", \"data\": {\"hi\": 1.02, \"lo\": 0.98}},\n",
    "                        {\"name\": \"staterror_CR\", \"type\": \"staterror\", \"data\": np.sqrt(cr_ttbar).tolist()},\n",
    "                    ],\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"wjets\",\n",
    "                    \"data\": cr_wjets.tolist(),\n",
    "                    \"modifiers\": [\n",
    "                        {\"name\": \"wjets_norm\", \"type\": \"normsys\", \"data\": {\"hi\": 1.10, \"lo\": 0.90}},\n",
    "                        {\"name\": \"lumi\", \"type\": \"normsys\", \"data\": {\"hi\": 1.02, \"lo\": 0.98}},\n",
    "                    ],\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "    \"observations\": [\n",
    "        {\"name\": \"SR\", \"data\": sr_data.tolist()},\n",
    "        {\"name\": \"CR\", \"data\": cr_data.tolist()},\n",
    "    ],\n",
    "    \"measurements\": [{\n",
    "        \"name\": \"meas\",\n",
    "        \"config\": {\"poi\": \"mu\", \"parameters\": []},\n",
    "    }],\n",
    "    \"version\": \"1.0.0\",\n",
    "}\n",
    "\n",
    "print(f\"Channels: {[ch['name'] for ch in workspace['channels']]}\")\n",
    "print(f\"SR bins: {len(sr_signal)}, CR bins: {len(cr_ttbar)}\")\n",
    "print(f\"Total expected (SR): {sr_total.sum():.1f}\")\n",
    "print(f\"Observed data (SR):  {sr_data.sum():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Model & Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nextstat.from_pyhf(workspace)\n",
    "\n",
    "print(f\"Parameters:  {model.n_params()}\")\n",
    "print(f\"Channels:    {model.n_channels()}\")\n",
    "print(f\"Total bins:  {model.n_bins()}\")\n",
    "print(f\"\\nParameter names:\")\n",
    "for i, name in enumerate(model.parameter_names()):\n",
    "    print(f\"  [{i}] {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workspace audit\n",
    "audit = nextstat.workspace_audit(json.dumps(workspace))\n",
    "print(f\"Channels:     {audit['n_channels']}\")\n",
    "print(f\"Samples:      {audit['n_samples']}\")\n",
    "print(f\"Modifiers:    {audit['n_modifiers']}\")\n",
    "print(f\"Unsupported:  {audit['n_unsupported']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MLE Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = nextstat.fit(model)\n",
    "\n",
    "print(f\"Converged: {fit.converged}\")\n",
    "print(f\"NLL:       {fit.nll:.4f}\")\n",
    "print(f\"\\nBest-fit parameters:\")\n",
    "names = model.parameter_names()\n",
    "for i, (name, val) in enumerate(zip(names, fit.params)):\n",
    "    print(f\"  {name:25s} = {val:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pulls & Constraints\n",
    "\n",
    "Nuisance parameter pulls show how much each parameter moved from its pre-fit value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulls_artifact = nextstat.pulls(model, fit)\n",
    "\n",
    "# Display as table\n",
    "print(f\"{'Parameter':25s} {'Pull':>8s} {'Constraint':>12s}\")\n",
    "print(\"-\" * 48)\n",
    "for entry in pulls_artifact['entries']:\n",
    "    print(f\"{entry['name']:25s} {entry['pull']:+8.3f} {entry['constraint']:12.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render pulls plot with native Rust renderer\n",
    "from IPython.display import SVG\n",
    "\n",
    "svg = nextstat.viz.render_svg(pulls_artifact, \"pulls\")\n",
    "SVG(svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Nuisance Parameter Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_entries = nextstat.ranking(model)\n",
    "ranking_artifact = nextstat.viz.ranking_arrays(ranking_entries)\n",
    "\n",
    "print(f\"Top-5 impacts on mu:\")\n",
    "for i in range(min(5, len(ranking_artifact['names']))):\n",
    "    name = ranking_artifact['names'][i]\n",
    "    up = ranking_artifact['delta_mu_up'][i]\n",
    "    down = ranking_artifact['delta_mu_down'][i]\n",
    "    print(f\"  {name:25s}  +{up:.4f} / {down:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg = nextstat.viz.render_svg(ranking_artifact, \"ranking\")\n",
    "SVG(svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_artifact = nextstat.corr(model, fit)\n",
    "\n",
    "# Filter to parameters with |corr| > 0.1\n",
    "corr_filtered = nextstat.viz.corr_subset(corr_artifact, top_n=10)\n",
    "\n",
    "svg = nextstat.viz.render_svg(corr_filtered, \"corr\")\n",
    "SVG(svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Pre/Post-Fit Distributions\n",
    "\n",
    "Stacked histograms showing data vs MC prediction, with ratio panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_artifact = nextstat.distributions(model, fit)\n",
    "\n",
    "print(f\"Channels in artifact: {len(dist_artifact['channels'])}\")\n",
    "for ch in dist_artifact['channels']:\n",
    "    print(f\"  {ch['name']}: {len(ch['samples'])} samples, {len(ch['bin_edges'])-1} bins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render SR channel distributions\n",
    "svg = nextstat.viz.render_svg(dist_artifact, \"distributions\")\n",
    "SVG(svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Profile Likelihood Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_values = np.linspace(0.0, 3.0, 31).tolist()\n",
    "profile = nextstat.profile_scan(model, mu_values, return_curve=True)\n",
    "\n",
    "# Find best-fit mu and 1-sigma interval\n",
    "mu_hat = profile['mu_hat']\n",
    "print(f\"Best-fit mu: {mu_hat:.3f}\")\n",
    "print(f\"NLL at best-fit: {profile['nll_hat']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg = nextstat.viz.render_svg(profile, \"profile\")\n",
    "SVG(svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. CLs Upper Limit (Brazil Band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_points = np.linspace(0.5, 4.0, 20).tolist()\n",
    "cls_result = nextstat.cls_curve(model, scan_points, alpha=0.05)\n",
    "\n",
    "print(f\"Observed 95% CL upper limit: mu < {cls_result['obs_limit']:.3f}\")\n",
    "print(f\"Expected 95% CL upper limit: mu < {cls_result['exp_limits'][2]:.3f}\")\n",
    "print(f\"Expected +1sigma:            mu < {cls_result['exp_limits'][1]:.3f}\")\n",
    "print(f\"Expected -1sigma:            mu < {cls_result['exp_limits'][3]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg = nextstat.viz.render_svg(cls_result, \"cls\")\n",
    "SVG(svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Theme Switching\n",
    "\n",
    "The native renderer supports 4 built-in themes. Pass a `config` dict to override defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATLAS style\n",
    "atlas_config = {\n",
    "    \"theme\": \"atlas\",\n",
    "    \"experiment\": {\n",
    "        \"name\": \"ATLAS\",\n",
    "        \"status\": \"Internal\",\n",
    "        \"sqrt_s_tev\": 13.6,\n",
    "        \"lumi_fb_inv\": 140,\n",
    "    },\n",
    "}\n",
    "\n",
    "svg_atlas = nextstat.viz.render_svg(pulls_artifact, \"pulls\", config=atlas_config)\n",
    "SVG(svg_atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMS style\n",
    "cms_config = {\n",
    "    \"theme\": \"cms\",\n",
    "    \"experiment\": {\n",
    "        \"name\": \"CMS\",\n",
    "        \"status\": \"Preliminary\",\n",
    "        \"sqrt_s_tev\": 13.6,\n",
    "        \"lumi_fb_inv\": 138,\n",
    "    },\n",
    "}\n",
    "\n",
    "svg_cms = nextstat.viz.render_svg(cls_result, \"cls\", config=cms_config)\n",
    "SVG(svg_cms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal theme (clean, no experiment label)\n",
    "svg_min = nextstat.viz.render_svg(profile, \"profile\", config={\"theme\": \"minimal\"})\n",
    "SVG(svg_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Export to File\n",
    "\n",
    "Save publication-quality plots as SVG, PDF, or PNG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"tutorial_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Export all major plot types\n",
    "plots = [\n",
    "    (pulls_artifact, \"pulls\", \"pulls.svg\"),\n",
    "    (ranking_artifact, \"ranking\", \"ranking.svg\"),\n",
    "    (corr_filtered, \"corr\", \"corr.svg\"),\n",
    "    (dist_artifact, \"distributions\", \"distributions.pdf\"),\n",
    "    (profile, \"profile\", \"profile.png\"),\n",
    "    (cls_result, \"cls\", \"cls.pdf\"),\n",
    "]\n",
    "\n",
    "for artifact, kind, filename in plots:\n",
    "    path = os.path.join(output_dir, filename)\n",
    "    nextstat.viz.render_to_file(artifact, kind, path, dpi=300)\n",
    "    size = os.path.getsize(path)\n",
    "    print(f\"  {filename:30s}  {size:>8,d} bytes\")\n",
    "\n",
    "print(f\"\\nAll plots saved to {output_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This tutorial demonstrated a complete statistical analysis workflow:\n",
    "\n",
    "| Step | API | Output |\n",
    "|------|-----|--------|\n",
    "| Load workspace | `nextstat.from_pyhf()` | `HistFactoryModel` |\n",
    "| Inspect | `model.parameter_names()`, `workspace_audit()` | Parameter list |\n",
    "| MLE Fit | `nextstat.fit()` | `FitResult` |\n",
    "| Pulls | `nextstat.pulls()` | Pull entries |\n",
    "| Ranking | `nextstat.ranking()` | Impact ranking |\n",
    "| Correlation | `nextstat.corr()` | Correlation matrix |\n",
    "| Distributions | `nextstat.distributions()` | Stacked histograms |\n",
    "| Profile scan | `nextstat.profile_scan()` | Likelihood scan |\n",
    "| CLs limit | `nextstat.cls_curve()` | Brazil band |\n",
    "| Render | `nextstat.viz.render_svg()` | SVG/PDF/PNG |\n",
    "\n",
    "### Key advantages over matplotlib rendering\n",
    "- Sub-millisecond SVG generation (vs 1-5s with matplotlib)\n",
    "- No Python dependency for rendering (pure Rust)\n",
    "- Built-in ATLAS/CMS/NextStat themes\n",
    "- Publication-ready PDF output with embedded fonts\n",
    "\n",
    "### Next steps\n",
    "- [Python API Reference](https://nextstat.io/docs/references/python-api)\n",
    "- [VizConfig Reference](https://nextstat.io/docs/references/viz-config)\n",
    "- [PyTorch Significance Loss Notebook](../notebooks/01_pytorch_significance_loss.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
