name: Python Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

concurrency:
  group: python-tests-${{ github.ref }}
  cancel-in-progress: true

env:
  CARGO_TERM_COLOR: always

jobs:
  docs-lint:
    name: Docs terminology lint
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Set up Python 3.13
        uses: actions/setup-python@v6
        with:
          python-version: '3.13'

      - name: Terminology lint (public docs)
        run: python3 scripts/docs/terminology_lint.py --check

  test:
    name: Python ${{ matrix.python-version }} on ${{ matrix.os }}
    # PR: github-hosted ubuntu, py3.13 only (1 job). Push main: self-hosted, full matrix.
    runs-on: ${{ github.event_name == 'pull_request' && 'ubuntu-latest' || fromJSON('["self-hosted","linux","x64","bench"]') }}
    strategy:
      fail-fast: false
      matrix:
        python-version: ${{ github.event_name == 'pull_request' && fromJSON('["3.13"]') || fromJSON('["3.11","3.12","3.13"]') }}
        # macOS only on push (self-hosted has no macOS; we test macOS wheels in release.yml)
        os: ['linux']

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v6
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@v1

      - name: Cache cargo
        uses: Swatinem/rust-cache@v2

      - name: Install maturin
        run: pip install "maturin>=1.11,<2.0"

      - name: Build Python package
        working-directory: bindings/ns-py
        run: maturin build --release

      - name: Install Python package
        working-directory: bindings/ns-py
        run: pip install target/wheels/*.whl

      - name: Upload wheel artifact (for validation-pack job)
        if: matrix.python-version == '3.13'
        uses: actions/upload-artifact@v4
        with:
          name: nextstat-wheel-linux-py${{ matrix.python-version }}
          path: bindings/ns-py/target/wheels/*.whl

      - name: Run Python tests
        run: |
          pip install "pytest>=9.0" "pytest-cov>=7.0" "numpy>=2.0" "pyhf>=0.7.6" "jsonschema>=4.0"
          pytest -q -m "not slow" tests/python

  validation-pack:
    name: Validation Pack (JSON/PDF determinism)
    # Only on push to main (not on every PR — saves ~15 min of compute).
    if: github.event_name == 'push'
    runs-on: ${{ fromJSON('["self-hosted","linux","x64","bench"]') }}
    needs: [docs-lint, test]
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Set up Python 3.13
        uses: actions/setup-python@v6
        with:
          python-version: '3.13'

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@v1

      - name: Cache cargo
        uses: Swatinem/rust-cache@v2

      - name: Download wheel artifact
        uses: actions/download-artifact@v4
        with:
          name: nextstat-wheel-linux-py3.13
          path: wheel/

      - name: Install Python package
        run: |
          python -m pip install --upgrade pip
          pip install wheel/*.whl

      - name: Build NextStat CLI (unbinned benchmark smoke)
        run: cargo build --release -p ns-cli

      - name: Render validation pack (JSON + PDF)
        run: |
          pip install "jsonschema>=4.0"
          mkdir -p artifacts artifacts2 artifacts_jsononly

          # JSON-only smoke (no matplotlib/PDF): prove the script can run in minimal environments.
          make validation-pack \
            VALIDATION_PACK_OUT_DIR=artifacts_jsononly \
            VALIDATION_PACK_WORKSPACE=tests/fixtures/simple_workspace.json \
            VALIDATION_PACK_ARGS="--python python --deterministic --json-only"
          python - <<'PY'
          import json
          from pathlib import Path
          import jsonschema
          schema = json.loads(Path("docs/schemas/validation/validation_report_v1.schema.json").read_text())
          inst = json.loads(Path("artifacts_jsononly/validation_report.json").read_text())
          jsonschema.validate(inst, schema)
          print("validation_report_v1 (json-only): schema ok")
          PY

          # PDF renderer dependency (runs via `python -m nextstat.validation_report`).
          pip install "matplotlib>=3.8"
          make validation-pack \
            VALIDATION_PACK_OUT_DIR=artifacts \
            VALIDATION_PACK_WORKSPACE=tests/fixtures/simple_workspace.json \
            VALIDATION_PACK_ARGS="--python python --deterministic"
          python - <<'PY'
          import json
          from pathlib import Path
          import jsonschema
          schema = json.loads(Path("docs/schemas/validation/validation_report_v1.schema.json").read_text())
          inst = json.loads(Path("artifacts/validation_report.json").read_text())
          jsonschema.validate(inst, schema)
          print("validation_report_v1: schema ok")
          PY

          # Determinism: re-render using the same Apex2 master input and ensure JSON+PDF are bit-identical.
          make validation-pack \
            VALIDATION_PACK_OUT_DIR=artifacts2 \
            VALIDATION_PACK_WORKSPACE=tests/fixtures/simple_workspace.json \
            VALIDATION_PACK_ARGS="--apex2-master artifacts/apex2_master_report.json --python python --deterministic"
          sha256sum artifacts/validation_report.json artifacts2/validation_report.json
          sha256sum artifacts/validation_report.pdf artifacts2/validation_report.pdf
          sha256sum artifacts/validation_pack_manifest.json artifacts2/validation_pack_manifest.json
          test "$(sha256sum artifacts/validation_report.json | awk '{print $1}')" = "$(sha256sum artifacts2/validation_report.json | awk '{print $1}')"
          test "$(sha256sum artifacts/validation_report.pdf | awk '{print $1}')" = "$(sha256sum artifacts2/validation_report.pdf | awk '{print $1}')"
          test "$(sha256sum artifacts/validation_pack_manifest.json | awk '{print $1}')" = "$(sha256sum artifacts2/validation_pack_manifest.json | awk '{print $1}')"

          # Snapshot index: stable list of artifact hashes for discovery/replication.
          python scripts/benchmarks/write_snapshot_index.py \
            --suite python-tests-validation-pack \
            --artifacts-dir artifacts \
            --out artifacts/snapshot_index.json

          # Unbinned benchmark contract smoke: deterministic toy run + schema validation.
          pip install "numpy>=2.0" "pyarrow>=18.0"
          NS_CLI_BIN=target/release/nextstat \
            python benchmarks/unbinned/run_suite.py \
            --cases gauss_exp \
            --n-events 2000 \
            --seed 42 \
            --out artifacts/unbinned_bench_smoke.json
          python - <<'PY'
          import json
          from pathlib import Path
          import jsonschema
          schema = json.loads(Path("docs/schemas/benchmarks/unbinned_run_suite_result_v1.schema.json").read_text())
          inst = json.loads(Path("artifacts/unbinned_bench_smoke.json").read_text())
          jsonschema.validate(inst, schema)
          print("unbinned_run_suite_result_v1: schema ok")
          PY

      - name: Find unbinned baseline artifact
        if: always()
        id: unbinned_baseline
        uses: actions/github-script@v8
        with:
          script: |
            const owner = context.repo.owner;
            const repo = context.repo.repo;
            const workflow_id = 'python-tests.yml';
            const artifact_name = 'validation-report-ubuntu-py3.13';
            const ref = context.ref || '';
            const branch = ref.startsWith('refs/heads/') ? ref.slice('refs/heads/'.length) : '';

            const runs = await github.rest.actions.listWorkflowRuns({
              owner,
              repo,
              workflow_id,
              status: 'success',
              ...(branch ? { branch } : {}),
              per_page: 1,
            });

            if (!runs.data.workflow_runs.length) {
              core.setOutput('found', 'false');
              return;
            }

            const run_id = runs.data.workflow_runs[0].id;
            if (run_id === context.runId) {
              core.setOutput('found', 'false');
              return;
            }

            const arts = await github.rest.actions.listWorkflowRunArtifacts({
              owner,
              repo,
              run_id,
              per_page: 100,
            });

            const a = arts.data.artifacts.find(x => x.name === artifact_name && !x.expired);
            if (!a) {
              core.setOutput('found', 'false');
              return;
            }

            core.setOutput('found', 'true');
            core.setOutput('run_id', String(run_id));
            core.setOutput('artifact_id', String(a.id));

      - name: Download baseline validation artifact
        if: steps.unbinned_baseline.outputs.found == 'true'
        uses: actions/github-script@v8
        with:
          script: |
            const fs = require('fs');
            const owner = context.repo.owner;
            const repo = context.repo.repo;
            const artifact_id = Number('${{ steps.unbinned_baseline.outputs.artifact_id }}');
            const download = await github.rest.actions.downloadArtifact({
              owner,
              repo,
              artifact_id,
              archive_format: 'zip',
            });
            fs.writeFileSync('baseline_artifact.zip', Buffer.from(download.data));

      - name: Compare unbinned smoke vs baseline
        if: always()
        run: |
          set -euo pipefail
          baseline_path="baseline/unbinned_bench_smoke.json"
          baseline_run_id="${{ steps.unbinned_baseline.outputs.run_id }}"
          baseline_found="${{ steps.unbinned_baseline.outputs.found }}"
          if [[ -z "${baseline_run_id}" ]]; then
            baseline_run_id="none"
          fi
          if [[ -z "${baseline_found}" ]]; then
            baseline_found="false"
          fi

          if [[ "${baseline_found}" == "true" ]]; then
            mkdir -p baseline
            unzip -q baseline_artifact.zip -d baseline
            discovered="$(find baseline -maxdepth 4 -name unbinned_bench_smoke.json | head -n 1 || true)"
            if [[ -n "${discovered}" ]]; then
              baseline_path="${discovered}"
            fi
          fi

          python3 scripts/benchmarks/compare_unbinned_bench.py \
            --baseline "${baseline_path}" \
            --current artifacts/unbinned_bench_smoke.json \
            --out artifacts/unbinned_bench_drift_summary.json \
            --case gauss_exp \
            --tool nextstat \
            --max-wall-regression-ratio 2.5 \
            --meta baseline_run_id="${baseline_run_id}" \
            --meta baseline_found="${baseline_found}"

      - name: Upload Apex2 report artifact
        uses: actions/upload-artifact@v4
        with:
          name: apex2-report-ubuntu-py3.13
          path: artifacts/*.json

      - name: Upload unified validation report artifacts
        uses: actions/upload-artifact@v4
        with:
          name: validation-report-ubuntu-py3.13
          path: |
            artifacts/validation_report.json
            artifacts/validation_report.pdf
            artifacts/validation_pack_manifest.json
            artifacts/snapshot_index.json
            artifacts/unbinned_bench_smoke.json
            artifacts/unbinned_bench_drift_summary.json

      - name: Upload validation pack determinism artifacts (debug)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: validation-report-determinism-ubuntu-py3.13
          path: |
            artifacts2/validation_report.json
            artifacts2/validation_report.pdf
            artifacts2/validation_pack_manifest.json
            artifacts_jsononly/validation_report.json
            artifacts_jsononly/validation_pack_manifest.json

  lint:
    name: Python Linting
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.11'

      - name: Install linting tools
        run: |
          pip install "ruff>=0.15" "mypy>=1.19"

      - name: Check formatting with ruff
        run: |
          ruff format --check bindings/ns-py/python

      - name: Lint with ruff
        run: ruff check bindings/ns-py/python

      - name: Type check with mypy
        run: mypy bindings/ns-py/python

  stub-generation:
    name: Generate Python Stubs
    # Only on push to main — stub drift doesn't need per-PR validation.
    if: github.event_name == 'push'
    runs-on: ${{ fromJSON('["self-hosted","linux","x64","bench"]') }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.11'

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@v1

      - name: Cache cargo
        uses: Swatinem/rust-cache@v2

      - name: Install maturin
        run: pip install "maturin>=1.11,<2.0"

      - name: Build and generate stubs
        working-directory: bindings/ns-py
        run: |
          maturin build --release
          pip install target/wheels/*.whl
          # Stub generation will be added in Phase 1
          echo "Python stub generation - will be added in Phase 1"
