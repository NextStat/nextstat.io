# HTCondor submit file: run Apex2 ROOT parity in a job array (one case per job).
#
# Requires `tests/apex2_root_suite_report.py --case-index`.
#
# Edit `initialdir` to point at your NextStat checkout on a shared filesystem.
#
# Required env vars on the submit node:
# - APEX2_ROOT_CASES_JSON: path to cases JSON (relative to initialdir or absolute)
# - APEX2_RESULTS_DIR: output directory (relative to initialdir or absolute)
#
# Optional:
# - APEX2_ROOT_SETUP: command to set up ROOT environment (see scripts/condor/README.md)
# - APEX2_PYTHON: python executable to use (e.g. from a venv/conda env)
# - APEX2_ROOT_DQ_ATOL: dq tolerance (optional)
# - APEX2_ROOT_MU_HAT_ATOL: mu_hat tolerance (optional)
#
# To choose array size, set `queue <N>` equal to the number of cases in your JSON.

universe = vanilla

initialdir = /path/to/nextstat.io
# Use bash explicitly so the wrapper does not need executable permissions.
executable = /bin/bash
arguments  = scripts/condor/run_apex2_root_suite_case.sh $(Process)

output = scripts/condor/logs/apex2_root_case_$(Cluster)_$(Process).out
error  = scripts/condor/logs/apex2_root_case_$(Cluster)_$(Process).err
log    = scripts/condor/logs/apex2_root_case_$(Cluster).log

request_cpus   = 4
request_memory = 8GB
request_disk   = 20GB

getenv = True

requirements = (TARGET.Arch == "X86_64") && (TARGET.OpSys == "LINUX")

# Limit how many jobs are materialized at once (optional):
max_materialize = 100

queue 10
