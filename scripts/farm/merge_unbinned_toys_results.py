#!/usr/bin/env python3
"""Merge shard outputs from distributed `unbinned-fit-toys` runs.

Primary input is `manifest.json` generated by
`scripts/farm/run_unbinned_fit_toys_cluster.py`.
"""

from __future__ import annotations

import argparse
import datetime as dt
import json
import math
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Any


@dataclass
class ShardInput:
    shard_index: int
    toy_start: int
    n_toys: int
    host: str
    output_path: Path
    raw: dict[str, Any]


def _is_finite_number(x: Any) -> bool:
    return isinstance(x, (int, float)) and math.isfinite(float(x))


def _pct(sorted_values: list[float], p: float) -> float:
    if len(sorted_values) == 1:
        return sorted_values[0]
    idx = int(round((len(sorted_values) - 1) * p))
    return sorted_values[idx]


def _load_json(path: Path) -> dict[str, Any]:
    return json.loads(path.read_text(encoding="utf-8"))


def _load_from_manifest(path: Path) -> tuple[list[ShardInput], dict[str, Any]]:
    manifest = _load_json(path)
    plans = manifest.get("plans") or []
    results = manifest.get("results") or []

    plan_by_idx: dict[int, dict[str, Any]] = {}
    for p in plans:
        if isinstance(p, dict) and isinstance(p.get("shard_index"), int):
            plan_by_idx[int(p["shard_index"])] = p

    out: list[ShardInput] = []
    for r in results:
        if not isinstance(r, dict):
            continue
        if r.get("status") != "ok":
            continue
        shard_index = int(r.get("shard_index"))
        output = r.get("local_output")
        if not isinstance(output, str) or not output:
            continue
        output_path = Path(output)
        if not output_path.exists():
            continue

        p = plan_by_idx.get(shard_index, {})
        toy_start = int(p.get("toy_start", 0))
        n_toys = int(p.get("n_toys", 0))
        host = str(r.get("host", p.get("host", "unknown")))
        raw = _load_json(output_path)

        out.append(
            ShardInput(
                shard_index=shard_index,
                toy_start=toy_start,
                n_toys=n_toys,
                host=host,
                output_path=output_path,
                raw=raw,
            )
        )

    out.sort(key=lambda x: (x.toy_start, x.shard_index))
    return out, manifest


def _load_from_paths(paths: list[Path]) -> list[ShardInput]:
    out: list[ShardInput] = []
    toy_start = 0
    for i, path in enumerate(paths):
        raw = _load_json(path)
        n_toys = int((raw.get("results") or {}).get("n_toys", 0))
        out.append(
            ShardInput(
                shard_index=i,
                toy_start=toy_start,
                n_toys=n_toys,
                host="unknown",
                output_path=path,
                raw=raw,
            )
        )
        toy_start += max(0, n_toys)
    return out


def _merge_pull_summary(pulls: list[float]) -> dict[str, Any] | None:
    if not pulls:
        return None
    n = float(len(pulls))
    mean = sum(pulls) / n
    var = sum((x - mean) * (x - mean) for x in pulls) / n
    std = math.sqrt(max(0.0, var))
    sorted_vals = sorted(pulls)
    return {
        "n_ok": len(pulls),
        "mean": mean,
        "std": std,
        "q16": _pct(sorted_vals, 0.16),
        "q50": _pct(sorted_vals, 0.50),
        "q84": _pct(sorted_vals, 0.84),
        "frac_abs_lt_1": sum(1 for x in pulls if abs(x) < 1.0) / n,
        "frac_abs_lt_2": sum(1 for x in pulls if abs(x) < 2.0) / n,
    }


def _merge_pulls_by_param(shards: list[ShardInput], n_params: int) -> dict[str, Any]:
    n_sum = [0] * n_params
    sum_x = [0.0] * n_params
    sum_x2 = [0.0] * n_params
    sum_f1 = [0.0] * n_params
    sum_f2 = [0.0] * n_params

    for shard in shards:
        summary = shard.raw.get("summary")
        if not isinstance(summary, dict):
            continue
        pbp = summary.get("pulls_by_param")
        if not isinstance(pbp, dict):
            continue
        n_ok = pbp.get("n_ok")
        mean = pbp.get("mean")
        std = pbp.get("std")
        f1 = pbp.get("frac_abs_lt_1")
        f2 = pbp.get("frac_abs_lt_2")
        if not all(isinstance(x, list) for x in [n_ok, mean, std, f1, f2]):
            continue

        for j in range(n_params):
            if j >= len(n_ok) or j >= len(mean) or j >= len(std) or j >= len(f1) or j >= len(f2):
                continue
            n_j = n_ok[j]
            m_j = mean[j]
            s_j = std[j]
            f1_j = f1[j]
            f2_j = f2[j]
            if not isinstance(n_j, int) or n_j <= 0:
                continue
            if not _is_finite_number(m_j) or not _is_finite_number(s_j):
                continue
            if not _is_finite_number(f1_j) or not _is_finite_number(f2_j):
                continue

            n_sum[j] += n_j
            m = float(m_j)
            s = float(s_j)
            sum_x[j] += n_j * m
            sum_x2[j] += n_j * (s * s + m * m)
            sum_f1[j] += n_j * float(f1_j)
            sum_f2[j] += n_j * float(f2_j)

    out_n: list[Any] = []
    out_mean: list[Any] = []
    out_std: list[Any] = []
    out_f1: list[Any] = []
    out_f2: list[Any] = []

    for j in range(n_params):
        if n_sum[j] <= 0:
            out_n.append(None)
            out_mean.append(None)
            out_std.append(None)
            out_f1.append(None)
            out_f2.append(None)
            continue
        n = float(n_sum[j])
        mean = sum_x[j] / n
        var = max(0.0, sum_x2[j] / n - mean * mean)
        out_n.append(n_sum[j])
        out_mean.append(mean)
        out_std.append(math.sqrt(var))
        out_f1.append(sum_f1[j] / n)
        out_f2.append(sum_f2[j] / n)

    return {
        "only_converged": True,
        "n_ok": out_n,
        "mean": out_mean,
        "std": out_std,
        "frac_abs_lt_1": out_f1,
        "frac_abs_lt_2": out_f2,
    }


def merge_shards(shards: list[ShardInput], manifest: dict[str, Any] | None) -> dict[str, Any]:
    if not shards:
        raise ValueError("no shard outputs to merge")

    first = shards[0].raw
    input_schema_version = first.get("input_schema_version")
    parameter_names = first.get("parameter_names")
    poi_index = first.get("poi_index")

    if not isinstance(parameter_names, list) or not isinstance(poi_index, int):
        raise ValueError("invalid shard JSON: missing parameter_names or poi_index")

    converged_all: list[Any] = []
    poi_hat_all: list[Any] = []
    poi_sigma_all: list[Any] = []
    nll_all: list[Any] = []

    n_toys_total = 0
    n_error_total = 0
    n_converged_total = 0
    n_nonconverged_total = 0

    poi_true: float | None = None

    for shard in shards:
        raw = shard.raw
        if raw.get("input_schema_version") != input_schema_version:
            raise ValueError(
                f"schema mismatch for {shard.output_path}: {raw.get('input_schema_version')} != {input_schema_version}"
            )
        if raw.get("parameter_names") != parameter_names:
            raise ValueError(f"parameter_names mismatch for {shard.output_path}")
        if raw.get("poi_index") != poi_index:
            raise ValueError(f"poi_index mismatch for {shard.output_path}")

        results = raw.get("results")
        if not isinstance(results, dict):
            raise ValueError(f"missing results in {shard.output_path}")

        n_toys = int(results.get("n_toys", 0))
        n_err = int(results.get("n_error", 0))
        n_conv = int(results.get("n_converged", 0))
        n_non = int(results.get("n_nonconverged", 0))

        conv = results.get("converged")
        poi_hat = results.get("poi_hat")
        poi_sigma = results.get("poi_sigma")
        nll = results.get("nll")

        if not (isinstance(conv, list) and isinstance(poi_hat, list) and isinstance(poi_sigma, list) and isinstance(nll, list)):
            raise ValueError(f"results arrays missing in {shard.output_path}")
        if not (len(conv) == len(poi_hat) == len(poi_sigma) == len(nll) == n_toys):
            raise ValueError(f"results array length mismatch in {shard.output_path}")

        pt = results.get("poi_true")
        if _is_finite_number(pt):
            ptf = float(pt)
            if poi_true is None:
                poi_true = ptf
            elif abs(poi_true - ptf) > 1e-12:
                raise ValueError(f"poi_true mismatch in {shard.output_path}")

        n_toys_total += n_toys
        n_error_total += n_err
        n_converged_total += n_conv
        n_nonconverged_total += n_non

        converged_all.extend(conv)
        poi_hat_all.extend(poi_hat)
        poi_sigma_all.extend(poi_sigma)
        nll_all.extend(nll)

    if n_toys_total != len(converged_all):
        raise ValueError("merged length mismatch")

    poi_hat_ok: list[float] = [float(x) for x in poi_hat_all if _is_finite_number(x)]
    summary: dict[str, Any] | None
    if not poi_hat_ok:
        summary = None
        pull_summary = None
        pulls_by_param = None
    else:
        n = float(len(poi_hat_ok))
        mean = sum(poi_hat_ok) / n
        var = sum((x - mean) * (x - mean) for x in poi_hat_ok) / n
        std = math.sqrt(max(0.0, var))
        sorted_hat = sorted(poi_hat_ok)

        pulls: list[float] = []
        if poi_true is not None:
            for i, hat in enumerate(poi_hat_all):
                if i >= len(converged_all):
                    break
                if i >= len(poi_sigma_all):
                    break
                if converged_all[i] is not True:
                    continue
                sig = poi_sigma_all[i]
                if not _is_finite_number(hat) or not _is_finite_number(sig):
                    continue
                sigf = float(sig)
                if sigf <= 0.0:
                    continue
                pulls.append((float(hat) - poi_true) / sigf)

        pull_summary = _merge_pull_summary(pulls)
        pulls_by_param = _merge_pulls_by_param(shards, n_params=len(parameter_names))
        summary = {
            "n_ok": len(poi_hat_ok),
            "mean": mean,
            "std": std,
            "q16": _pct(sorted_hat, 0.16),
            "q50": _pct(sorted_hat, 0.50),
            "q84": _pct(sorted_hat, 0.84),
            "pull": pull_summary,
            "pulls_by_param": pulls_by_param,
        }

    guard_failures: list[str] = []
    guard_passed = True
    require_all_converged = False
    max_abs_poi_pull_mean = None
    poi_pull_std_range = None

    for shard in shards:
        g = shard.raw.get("guardrails")
        if not isinstance(g, dict):
            continue
        if g.get("passed") is False:
            guard_passed = False
        if g.get("require_all_converged") is True:
            require_all_converged = True
        if max_abs_poi_pull_mean is None and g.get("max_abs_poi_pull_mean") is not None:
            max_abs_poi_pull_mean = g.get("max_abs_poi_pull_mean")
        if poi_pull_std_range is None and g.get("poi_pull_std_range") is not None:
            poi_pull_std_range = g.get("poi_pull_std_range")
        failures = g.get("failures")
        if isinstance(failures, list):
            for f in failures:
                guard_failures.append(f"shard {shard.shard_index} ({shard.host}): {f}")

    if guard_failures:
        guard_passed = False

    poi_pull_mean = summary.get("pull", {}).get("mean") if isinstance(summary, dict) and isinstance(summary.get("pull"), dict) else None
    poi_pull_std = summary.get("pull", {}).get("std") if isinstance(summary, dict) and isinstance(summary.get("pull"), dict) else None

    gen_first = first.get("gen")
    gen_out: dict[str, Any]
    if isinstance(gen_first, dict):
        gen_out = {
            "point": gen_first.get("point"),
            "params": gen_first.get("params"),
            "overrides": gen_first.get("overrides"),
            "seed": manifest.get("seed") if isinstance(manifest, dict) else gen_first.get("seed"),
            "n_toys": n_toys_total,
        }
    else:
        gen_out = {
            "point": None,
            "params": None,
            "overrides": {},
            "seed": manifest.get("seed") if isinstance(manifest, dict) else None,
            "n_toys": n_toys_total,
        }

    output = {
        "input_schema_version": input_schema_version,
        "parameter_names": parameter_names,
        "poi_index": poi_index,
        "gen": gen_out,
        "results": {
            "n_toys": n_toys_total,
            "n_error": n_error_total,
            "n_converged": n_converged_total,
            "n_nonconverged": n_nonconverged_total,
            "converged": converged_all,
            "poi_true": poi_true,
            "poi_hat": poi_hat_all,
            "poi_sigma": poi_sigma_all,
            "nll": nll_all,
        },
        "summary": summary,
        "guardrails": {
            "passed": guard_passed,
            "failures": guard_failures,
            "require_all_converged": require_all_converged,
            "max_abs_poi_pull_mean": max_abs_poi_pull_mean,
            "poi_pull_mean": poi_pull_mean,
            "poi_pull_std": poi_pull_std,
            "poi_pull_std_range": poi_pull_std_range,
        },
        "merge": {
            "schema_version": "nextstat.cpu_farm_unbinned_fit_toys_merged.v1",
            "created_at_utc": dt.datetime.now(tz=dt.timezone.utc).isoformat(),
            "n_shards": len(shards),
            "sources": [
                {
                    "shard_index": s.shard_index,
                    "host": s.host,
                    "toy_start": s.toy_start,
                    "n_toys": s.n_toys,
                    "path": str(s.output_path),
                }
                for s in shards
            ],
        },
    }

    if manifest is not None:
        output["merge"]["manifest"] = {
            "run_id": manifest.get("run_id"),
            "path": str(manifest.get("_path", "")),
            "hosts_file": manifest.get("hosts_file"),
        }

    return output


def parse_args() -> argparse.Namespace:
    ap = argparse.ArgumentParser(description="Merge cluster shard outputs for unbinned-fit-toys.")
    ap.add_argument("--manifest", type=Path, default=None, help="manifest.json from farm runner")
    ap.add_argument("--input", action="append", default=[], type=Path, help="direct shard out.json path (repeat)")
    ap.add_argument("--out", required=True, type=Path)
    return ap.parse_args()


def main() -> int:
    args = parse_args()

    if args.manifest is None and not args.input:
        raise SystemExit("provide --manifest or at least one --input")

    manifest = None
    if args.manifest is not None:
        shards, manifest = _load_from_manifest(args.manifest)
        manifest["_path"] = str(args.manifest)
    else:
        shards = _load_from_paths(args.input)

    if not shards:
        raise SystemExit("no successful shard outputs found")

    merged = merge_shards(shards, manifest)
    args.out.parent.mkdir(parents=True, exist_ok=True)
    args.out.write_text(json.dumps(merged, indent=2), encoding="utf-8")

    res = merged["results"]
    print(f"Wrote {args.out}")
    print(
        "n_toys={n_toys} n_converged={n_converged} n_nonconverged={n_nonconv} n_error={n_error}".format(
            n_toys=res.get("n_toys"),
            n_converged=res.get("n_converged"),
            n_nonconv=res.get("n_nonconverged"),
            n_error=res.get("n_error"),
        )
    )
    return 0


if __name__ == "__main__":
    sys.exit(main())
