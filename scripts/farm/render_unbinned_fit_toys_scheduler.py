#!/usr/bin/env python3
"""Generate SLURM/HTCondor job files for `nextstat unbinned-fit-toys --shard`.

This is a scheduler bridge for PF3.2: it produces the same `manifest.json` style
artifact as the SSH launcher, but without requiring host-level access.
"""

from __future__ import annotations

import argparse
import datetime as dt
import json
import os
import posixpath
import shlex
from dataclasses import asdict, dataclass
from pathlib import Path
from typing import Any


@dataclass
class ShardPlan:
    shard_index: int
    host: str
    user: str | None
    port: int
    weight: float
    threads: int
    toy_start: int
    n_toys: int
    seed: int


def split_shard_range(n_toys: int, shard_index: int, shard_total: int) -> tuple[int, int]:
    per = n_toys // shard_total
    rem = n_toys % shard_total
    start = shard_index * per + min(shard_index, rem)
    count = per + (1 if shard_index < rem else 0)
    return start, count


def _write(path: Path, text: str) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(text, encoding="utf-8")


def _extract_unbinned_channel_data_files(config_abs: Path) -> list[tuple[str, str]]:
    """Extract (src_abs, dest_rel) for channel data files referenced by a JSON spec.

    - `src_abs` is an absolute path on the submit node.
    - `dest_rel` is the relative path inside the job sandbox after we place the config
      under `specs/<config_base>`. This preserves the spec's relative file layout.
    """
    if config_abs.suffix.lower() != ".json":
        return []

    try:
        cfg = json.loads(config_abs.read_text(encoding="utf-8"))
    except Exception:
        return []

    channels = cfg.get("channels")
    if not isinstance(channels, list):
        return []

    out: list[tuple[str, str]] = []
    for ch in channels:
        if not isinstance(ch, dict):
            continue
        data = ch.get("data")
        if not isinstance(data, dict):
            continue
        file_v = data.get("file")
        if not isinstance(file_v, str) or not file_v:
            continue

        # Resolve source path relative to the config directory on submit node.
        src_abs = file_v
        if not os.path.isabs(src_abs):
            src_abs = str((config_abs.parent / src_abs).resolve())

        # Destination path inside sandbox: config is placed in ./specs/<config_base>,
        # so config_dir is ./specs. Preserve the spec's relative reference by staging
        # files under normpath("specs/<file_v>").
        dest_rel = posixpath.normpath(posixpath.join("specs", file_v))

        out.append((src_abs, dest_rel))
    return out


def render_slurm(run_dir: Path, shards: int, cpus_per_task: int, time_limit: str | None) -> None:
    # Single array job for all shards.
    out_flag = f"#SBATCH --output={shlex.quote(str(run_dir / 'slurm-%A_%a.out'))}"
    err_flag = f"#SBATCH --error={shlex.quote(str(run_dir / 'slurm-%A_%a.err'))}"
    time_flag = f"#SBATCH --time={time_limit}" if time_limit else ""
    cpus_flag = f"#SBATCH --cpus-per-task={cpus_per_task}" if cpus_per_task > 0 else ""

    script = f"""#!/usr/bin/env bash
set -euo pipefail

# Auto-generated by scripts/farm/render_unbinned_fit_toys_scheduler.py
# Run dir: {shlex.quote(str(run_dir))}

#SBATCH --job-name=nextstat_unbinned_fit_toys
#SBATCH --array=0-{shards - 1}
{out_flag}
{err_flag}
{cpus_flag}
{time_flag}

export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

IDX="${{SLURM_ARRAY_TASK_ID}}"
HOST="$(hostname -s 2>/dev/null || hostname)"

RUN_DIR={shlex.quote(str(run_dir))}

echo "$HOST" > "$RUN_DIR/shard_${{IDX}}.host"
start_ts="$(date +%s)"

set +e
bash "$RUN_DIR/run_one_shard.sh" "$IDX"
rc="$?"
set -e

end_ts="$(date +%s)"
echo "$rc" > "$RUN_DIR/shard_${{IDX}}.rc"
echo "$((end_ts - start_ts))" > "$RUN_DIR/shard_${{IDX}}.elapsed_s"

exit "$rc"
"""
    _write(run_dir / "slurm_array_job.sh", script)
    os.chmod(run_dir / "slurm_array_job.sh", 0o755)


def render_htcondor(
    run_dir: Path,
    shards: int,
    request_cpus: int,
    request_memory: str | None,
    requirements: str | None,
    config_abs: Path,
    nextstat_bin_abs: str,
    transfer_input_files: list[str],
) -> None:
    # Two variants:
    # - sharedfs: execute nodes can read `nextstat_bin` and `config` by absolute path
    # - transfer: transfer `nextstat_bin`, `config`, and scripts into the job sandbox
    req_cpus_line = f"request_cpus = {request_cpus}" if request_cpus > 0 else ""
    req_mem_line = f"request_memory = {request_memory}" if request_memory else ""
    reqs_line = f"requirements = {requirements}" if requirements else ""

    sharedfs_submit = f"""# Auto-generated by scripts/farm/render_unbinned_fit_toys_scheduler.py
# Mode: shared filesystem (no file transfer). Execute nodes must see:
#   - nextstat binary path from manifest.json
#   - config path from manifest.json
universe   = vanilla
initialdir = {run_dir}
executable = {run_dir}/condor_run_one_shard.sh
arguments  = $(Process)

should_transfer_files = NO

output = condor.$(Cluster).$(Process).out
error  = condor.$(Cluster).$(Process).err
log    = condor.$(Cluster).log

{req_cpus_line}
{req_mem_line}
{reqs_line}

queue {shards}
"""
    sharedfs_submit += "\n"
    _write(run_dir / "condor_job.sub", sharedfs_submit)

    # In transfer mode, HTCondor will place transferred input files in the job sandbox
    # with their basenames, so the runner must refer to them by basename as well.
    config_in = str(config_abs)
    bin_in = str(nextstat_bin_abs)

    transfer_submit = f"""# Auto-generated by scripts/farm/render_unbinned_fit_toys_scheduler.py
# Mode: file transfer. Transfers nextstat+config+scripts into the job sandbox.
universe   = vanilla
initialdir = {run_dir}
executable = {run_dir}/condor_run_one_shard_transfer.sh
arguments  = $(Process)

should_transfer_files = YES
transfer_executable = True
when_to_transfer_output = ON_EXIT
# The execute node may not see any of the absolute paths from manifest.json,
# so transfer the binary+spec into the sandbox (they will land as basenames).
transfer_input_files = {", ".join(transfer_input_files)}
transfer_output_files = shard_$(Process).out.json, shard_$(Process).metrics.json, shard_$(Process).stdout, shard_$(Process).stderr, shard_$(Process).rc, shard_$(Process).elapsed_s, shard_$(Process).host

output = condor.$(Cluster).$(Process).out
error  = condor.$(Cluster).$(Process).err
log    = condor.$(Cluster).log

{req_cpus_line}
{req_mem_line}
{reqs_line}

queue {shards}
"""
    transfer_submit += "\n"
    _write(run_dir / "condor_job_transfer.sub", transfer_submit)

    wrapper_sharedfs = f"""#!/usr/bin/env bash
set -euo pipefail

# Auto-generated by scripts/farm/render_unbinned_fit_toys_scheduler.py
# Mode: shared filesystem

IDX="$1"
HOST="$(hostname -s 2>/dev/null || hostname)"
RUN_DIR={shlex.quote(str(run_dir))}

echo "$HOST" > "$RUN_DIR/shard_${{IDX}}.host"
start_ts="$(date +%s)"

set +e
bash "$RUN_DIR/run_one_shard.sh" "$IDX"
rc="$?"
set -e

end_ts="$(date +%s)"
echo "$rc" > "$RUN_DIR/shard_${{IDX}}.rc"
echo "$((end_ts - start_ts))" > "$RUN_DIR/shard_${{IDX}}.elapsed_s"

exit "$rc"
"""
    _write(run_dir / "condor_run_one_shard.sh", wrapper_sharedfs)
    os.chmod(run_dir / "condor_run_one_shard.sh", 0o755)

    wrapper_transfer = """#!/usr/bin/env bash
set -euo pipefail

# Auto-generated by scripts/farm/render_unbinned_fit_toys_scheduler.py
# Mode: file transfer (runs inside job sandbox)

IDX="$1"
HOST="$(hostname -s 2>/dev/null || hostname)"

OUT_JSON="shard_${IDX}.out.json"
METRICS_JSON="shard_${IDX}.metrics.json"
STDOUT="shard_${IDX}.stdout"
STDERR="shard_${IDX}.stderr"

echo "$HOST" > "shard_${IDX}.host"
start_ts="$(date +%s)"

set +e
bash "./run_one_shard_transfer.sh" "$IDX"
rc="$?"
set -e

end_ts="$(date +%s)"
echo "$rc" > "shard_${IDX}.rc"
echo "$((end_ts - start_ts))" > "shard_${IDX}.elapsed_s"

# Ensure expected artifacts exist so HTCondor output transfer doesn't hold the job on failure.
touch "$STDOUT" "$STDERR" 2>/dev/null || true
if [ ! -f "$OUT_JSON" ]; then
    printf '{\"error\":\"job failed before producing out.json\",\"rc\":%s}\\n' \"$rc\" > \"$OUT_JSON\"
fi
if [ ! -f "$METRICS_JSON" ]; then
    printf '{\"error\":\"job failed before producing metrics.json\",\"rc\":%s}\\n' \"$rc\" > \"$METRICS_JSON\"
fi

exit "$rc"
"""
    _write(run_dir / "condor_run_one_shard_transfer.sh", wrapper_transfer)
    os.chmod(run_dir / "condor_run_one_shard_transfer.sh", 0o755)


def main() -> int:
    ap = argparse.ArgumentParser(description="Render SLURM/HTCondor jobs for unbinned-fit-toys shards.")
    ap.add_argument("--scheduler", choices=["slurm", "htcondor"], required=True)
    ap.add_argument("--config", type=Path, required=True, help="unbinned spec (JSON/YAML)")
    ap.add_argument("--n-toys", type=int, required=True)
    ap.add_argument("--seed", type=int, default=42)
    ap.add_argument("--shards", type=int, required=True, help="total shard count (INDEX/TOTAL)")
    ap.add_argument("--threads", type=int, default=0, help="nextstat --threads (0=auto)")
    ap.add_argument("--nextstat-bin", type=str, required=True)
    ap.add_argument("--out-dir", type=Path, required=True)
    ap.add_argument("--run-id", type=str, default=None)

    # SLURM knobs (optional)
    ap.add_argument("--slurm-cpus-per-task", type=int, default=0)
    ap.add_argument("--slurm-time", type=str, default=None, help="e.g. 02:00:00")

    # HTCondor knobs (optional)
    ap.add_argument("--condor-request-cpus", type=int, default=0)
    ap.add_argument("--condor-request-memory", type=str, default=None, help='e.g. "2GB"')
    ap.add_argument("--condor-requirements", type=str, default=None, help='HTCondor requirements expression')

    args = ap.parse_args()

    if args.n_toys <= 0:
        raise SystemExit("--n-toys must be > 0")
    if args.shards <= 0:
        raise SystemExit("--shards must be > 0")
    if args.seed < 0:
        raise SystemExit("--seed must be >= 0")

    run_id = args.run_id or dt.datetime.now(tz=dt.timezone.utc).strftime("schedfarm_%Y%m%dT%H%M%SZ")
    run_dir = args.out_dir / run_id
    run_dir.mkdir(parents=True, exist_ok=True)

    config_abs = args.config.expanduser().resolve()
    nextstat_bin_abs = os.path.abspath(os.path.expanduser(args.nextstat_bin))

    # For HTCondor transfer-mode, stage any channel data files into the sandbox.
    extra_data_files = _extract_unbinned_channel_data_files(config_abs)
    missing = [src for (src, _dest) in extra_data_files if not os.path.exists(src)]
    if missing:
        raise SystemExit(f"config references missing data files: {missing[:3]}{'...' if len(missing) > 3 else ''}")

    # Deterministic shard plan identical to `cmd_unbinned_fit_toys` split logic.
    plans: list[ShardPlan] = []
    for i in range(args.shards):
        start, count = split_shard_range(args.n_toys, i, args.shards)
        plans.append(
            ShardPlan(
                shard_index=i,
                host=args.scheduler,
                user=None,
                port=0,
                weight=1.0,
                threads=int(args.threads),
                toy_start=start,
                n_toys=count,
                seed=int(args.seed) + start,
            )
        )

    # Per-shard runner called by scheduler wrappers.
    run_one = f"""#!/usr/bin/env bash
set -euo pipefail

IDX="$1"
RUN_DIR={shlex.quote(str(run_dir))}

OUT_JSON="$RUN_DIR/shard_${{IDX}}.out.json"
METRICS_JSON="$RUN_DIR/shard_${{IDX}}.metrics.json"
STDOUT="$RUN_DIR/shard_${{IDX}}.stdout"
STDERR="$RUN_DIR/shard_${{IDX}}.stderr"

export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

{shlex.quote(nextstat_bin_abs)} unbinned-fit-toys \\
  --config {shlex.quote(str(config_abs))} \\
  --n-toys {args.n_toys} \\
  --seed {args.seed} \\
  --threads {args.threads} \\
  --shard "${{IDX}}/{args.shards}" \\
  --log-level warn \\
  --json-metrics "$METRICS_JSON" \\
  -o "$OUT_JSON" \\
  >"$STDOUT" \\
  2>"$STDERR"
"""
    _write(run_dir / "run_one_shard.sh", run_one)
    os.chmod(run_dir / "run_one_shard.sh", 0o755)

    # Transfer-mode runner: expects the binary and config to be transferred with their basenames.
    config_base = config_abs.name
    bin_base = Path(nextstat_bin_abs).name
    # Stage config and any referenced data files under a `specs/` dir so that
    # relative paths like `../artifacts/...` resolve correctly.
    stage_lines: list[str] = [
        "mkdir -p specs",
        f"mv ./{shlex.quote(config_base)} ./specs/{shlex.quote(config_base)}",
    ]
    for (_src_abs, dest_rel) in extra_data_files:
        base = os.path.basename(_src_abs)
        stage_lines.append(f"mkdir -p {shlex.quote(posixpath.dirname(dest_rel))}")
        stage_lines.append(f"cp -f ./{shlex.quote(base)} {shlex.quote(dest_rel)}")
    stage_block = "\n".join(stage_lines)

    run_one_transfer = f"""#!/usr/bin/env bash
set -euo pipefail

IDX="$1"

OUT_JSON="shard_${{IDX}}.out.json"
METRICS_JSON="shard_${{IDX}}.metrics.json"
STDOUT="shard_${{IDX}}.stdout"
STDERR="shard_${{IDX}}.stderr"

export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

# Stage spec + data files into an on-sandbox layout that preserves relative paths.
{stage_block}

# HTCondor file-transfer mode may drop execute bits depending on config; ensure it's runnable.
chmod +x ./{shlex.quote(bin_base)} 2>/dev/null || true

./{shlex.quote(bin_base)} unbinned-fit-toys \\
  --config ./specs/{shlex.quote(config_base)} \\
  --n-toys {args.n_toys} \\
  --seed {args.seed} \\
  --threads {args.threads} \\
  --shard "${{IDX}}/{args.shards}" \\
  --log-level warn \\
  --json-metrics "$METRICS_JSON" \\
  -o "$OUT_JSON" \\
  >"$STDOUT" \\
  2>"$STDERR"
"""
    _write(run_dir / "run_one_shard_transfer.sh", run_one_transfer)
    os.chmod(run_dir / "run_one_shard_transfer.sh", 0o755)

    if args.scheduler == "slurm":
        render_slurm(
            run_dir,
            shards=args.shards,
            cpus_per_task=int(args.slurm_cpus_per_task),
            time_limit=args.slurm_time,
        )
    else:
        # HTCondor transfer-mode inputs: run script + config + binary + any referenced data files.
        transfer_inputs = [
            str(run_dir / "run_one_shard_transfer.sh"),
            str(config_abs),
            str(nextstat_bin_abs),
        ]
        for (src_abs, _dest_rel) in extra_data_files:
            transfer_inputs.append(str(src_abs))

        render_htcondor(
            run_dir,
            shards=args.shards,
            request_cpus=int(args.condor_request_cpus),
            request_memory=args.condor_request_memory,
            requirements=args.condor_requirements,
            config_abs=config_abs,
            nextstat_bin_abs=nextstat_bin_abs,
            transfer_input_files=transfer_inputs,
        )

    manifest: dict[str, Any] = {
        "schema_version": "nextstat.cpu_farm_unbinned_fit_toys_run.v1",
        "created_at_utc": dt.datetime.now(tz=dt.timezone.utc).isoformat(),
        "run_id": run_id,
        "scheduler": args.scheduler,
        "config": str(config_abs),
        "n_toys": int(args.n_toys),
        "seed": int(args.seed),
        "threads": int(args.threads),
        "shards": int(args.shards),
        "nextstat_bin": nextstat_bin_abs,
        "run_dir": str(run_dir),
        "plans": [asdict(p) for p in plans],
        "results": [],
    }
    _write(run_dir / "manifest.json", json.dumps(manifest, indent=2) + "\n")

    print(f"run_id={run_id}")
    print(f"run_dir={run_dir}")
    print("wrote manifest.json and scheduler job files")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
