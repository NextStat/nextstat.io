---
title: "Route C Quickstart (Parquet/Arrow data-lake)"
status: draft
---

# Route C: Parquet/Arrow Data-Lake Quickstart

Goal: run HistFactory-style fit workflow from Parquet/Arrow without ROOT in the user flow.

This route uses:

- `docs/guides/fixtures/route_c/histograms_table.example.csv`
- `docs/guides/fixtures/route_c/build_histograms_parquet_example.py`

## 0) Optional Python deps for this route

```bash
python3 -m pip install pyarrow polars duckdb
```

## 1) Build example Parquet from CSV table

```bash
python3 docs/guides/fixtures/route_c/build_histograms_parquet_example.py
```

This writes:

- `docs/guides/fixtures/route_c/histograms.parquet`

## 2) from_parquet -> fit (Python API)

```python
import csv
import json
from pathlib import Path

import nextstat

observations = {"SR": [55.0, 65.0]}

model = nextstat.from_parquet(
    "docs/guides/fixtures/route_c/histograms.parquet",
    poi="mu",
    observations=observations,
)

fit = nextstat.fit(model)
mu_values = [i * 5.0 / 40.0 for i in range(41)]
scan = nextstat.profile_scan(model, mu_values)
cls = nextstat.cls_curve(model, mu_values)
mu_up = nextstat.upper_limit(model)

Path("tmp/guides/route_c").mkdir(parents=True, exist_ok=True)

fit_out = {
    "bestfit": [float(x) for x in fit.bestfit],
    "parameters": [float(x) for x in fit.parameters],
    "parameter_names": list(model.parameter_names()),
    "uncertainties": [float(x) for x in fit.uncertainties],
    "nll": float(fit.nll),
    "converged": bool(fit.converged),
}
Path("tmp/guides/route_c/fit_result.json").write_text(
    json.dumps(fit_out, indent=2, sort_keys=True) + "\n",
    encoding="utf-8",
)
Path("tmp/guides/route_c/scan_points.json").write_text(
    json.dumps(scan, indent=2, sort_keys=True) + "\n",
    encoding="utf-8",
)
Path("tmp/guides/route_c/cls_curve.json").write_text(
    json.dumps(cls, indent=2, sort_keys=True) + "\n",
    encoding="utf-8",
)

upper = {
    "alpha": float(cls["alpha"]),
    "exp_limits": [float(x) for x in cls["exp_limits"]],
    "mode": "scan",
    "mu_up": float(mu_up),
    "obs_limit": float(cls["obs_limit"]),
    "scan": {"start": 0.0, "stop": 5.0, "points": len(mu_values)},
}
Path("tmp/guides/route_c/upper_limit_scan.json").write_text(
    json.dumps(upper, indent=2, sort_keys=True) + "\n",
    encoding="utf-8",
)

with Path("tmp/guides/route_c/scan_points.csv").open("w", newline="", encoding="utf-8") as f:
    w = csv.DictWriter(f, fieldnames=["mu", "q_mu", "nll_mu", "converged", "n_iter"])
    w.writeheader()
    for r in scan["points"]:
        w.writerow({k: r.get(k) for k in w.fieldnames})
```

## 3) Polars/DuckDB -> Arrow -> fit (Python API)

```python
import duckdb
import nextstat
import polars as pl

# Polars -> Arrow
pl_df = pl.read_parquet("docs/guides/fixtures/route_c/histograms.parquet")
model_a = nextstat.from_arrow(pl_df.to_arrow(), poi="mu", observations={"SR": [55.0, 65.0]})

# DuckDB -> Arrow
con = duckdb.connect()
reader = con.execute("SELECT * FROM 'docs/guides/fixtures/route_c/histograms.parquet'").arrow()
model_b = nextstat.from_arrow(reader.read_all(), poi="mu", observations={"SR": [55.0, 65.0]})

fit_a = nextstat.fit(model_a)
fit_b = nextstat.fit(model_b)

# Consistency check across Arrow producers:
assert abs(fit_a.bestfit[0] - fit_b.bestfit[0]) < 1e-12
```

## 4) Export results back to Parquet (scan + CLs)

```python
import json
from pathlib import Path
import pyarrow as pa
import pyarrow.parquet as pq

Path("tmp/guides").mkdir(parents=True, exist_ok=True)

with open("tmp/guides/route_c/scan_points.json", "r", encoding="utf-8") as f:
    scan = json.load(f)
with open("tmp/guides/route_c/cls_curve.json", "r", encoding="utf-8") as f:
    cls = json.load(f)

rows = scan["points"]
scan_tbl = pa.table({
    "mu": [r["mu"] for r in rows],
    "q_mu": [r["q_mu"] for r in rows],
    "nll_mu": [r["nll_mu"] for r in rows],
    "converged": [r["converged"] for r in rows],
})

pq.write_table(scan_tbl, "tmp/guides/route_c_scan_points.parquet", compression="zstd")

cls_tbl = pa.table({
    "mu": [float(x) for x in cls["mu_values"]],
    "cls_obs": [float(x) for x in cls["cls_obs"]],
})
pq.write_table(cls_tbl, "tmp/guides/route_c_cls_curve.parquet", compression="zstd")
```

## Expected outputs (reference)

Core outputs generated by this quickstart:

- `docs/guides/fixtures/route_c/fit_result.json`
- `docs/guides/fixtures/route_c/upper_limit_scan.json`
- `docs/guides/fixtures/route_c/scan_points.json`
- `docs/guides/fixtures/route_c/scan_points.csv`
- `docs/guides/fixtures/route_c/cls_curve.json`

Legacy diagnostics bundle (optional, not produced by this pure Python quickstart):

- `docs/guides/fixtures/route_c/pulls.json`
- `docs/guides/fixtures/route_c/corr.json`
- `docs/guides/fixtures/route_c/reference_plot.png`
- `docs/guides/fixtures/route_c/validation_report_snippet.json`
